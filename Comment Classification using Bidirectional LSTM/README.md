In this project a neural network model for toxic comment classification is build. It is a multi-label classification problem where each comment can have multiple labels (possibly more than one) from the following six labels: toxic, severe_toxic, obscene, threat, insult, identity hate. The dataset can be downloaded from here (https://www.kaggle.com/c/jigsaw-toxiccomment-classification-challenge/data). The train.csv file contains both comments and labels for the training data, the test.csv file contains comments for test data and test_labels.csv file contains labels for test data. Split the training data in 80:20 to create training (80%) and validation (20%) set.

For the multi-label classification, the last layer should train six (one for each label type) separate binary classifier. That means the size of last Dense layer should be 6 and activation should be ‘sigmoid’.
The experiment has Bidirectional LSTM, multiple layers of Bidirectional LSTM, different embedding dimensionality, different mini-batch size, different hidden vector size for LSTM/GRU, different epoch, and choose the combination that yields highest accuracy without overfitting. To make sure that the model is not overfitting, difference 
between training accuracy and validation accuracy should not be more than 2%.
